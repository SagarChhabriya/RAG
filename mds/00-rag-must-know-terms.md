<!--
1. Query: The input or question guiding retrieval
2. Chunk: A small segment of a document for efficiency
3. Chunking: Breaking down text into meaningful segments
4. Embedding: A numerical representation capturing semantic meaning
5. Indexing: Organizing embeddings for fast retrieval
6. Vector Store: A database for storing text embeddings as vectors
7. Retrieval: Fetching relevant information based on a query
8. Semantic Search: Finding results based on meaning
9. Keyword Search: A method matching exact words or phrases without semantic understanding
10. Hybrid Search: Combines keyword and semantic search for balanced precision and recall
11. Augmentation: Enchances queries with retrieved information for better LLM responses
12. Context: Information from documents and queries aiding LLM relevance
13. Context Window: Maximum tokens an LLM processes at once (input and output context window)
14. Prompt: Formatted input for LLM response, including query and context
15. Prompt Engineering: Desining prompts for clarity and intext to improve outputs
16. Generation: LLM process of producing text from a prompt
17. Large Language Model (LLM): A neural network for language understanding and generation
18. Temperature: A parameter contorlling randomness
19. Response: The output generated by the model influenced by various factors
!-->

# Terminology Guide

1. **Query**: The input or question used to guide the retrieval process.
2. **Chunk**: A small segment or portion of a document, used to improve processing efficiency.
3. **Chunking**: The process of breaking down large texts into smaller, meaningful segments.
4. **Embedding**: A numerical vector representation that captures the semantic meaning of text.
5. **Indexing**: The process of organizing embeddings to enable fast and efficient retrieval.
6. **Vector Store**: A database designed to store text embeddings as vectors for quick access.
7. **Retrieval**: The action of fetching relevant information based on a given query.
8. **Semantic Search**: A search method that finds results based on the meaning, not just exact matches.
9. **Keyword Search**: A search method that looks for exact words or phrases, without considering semantic meaning.
10. **Hybrid Search**: A combination of both keyword and semantic search, aiming to balance precision and recall.
11. **Augmentation**: Enhancing a query with additional retrieved information to improve LLM responses.
12. **Context**: The relevant information from both documents and queries that helps to shape LLM output.
13. **Context Window**: The maximum number of tokens (words or characters) an LLM can process at once (includes both input and output).
14. **Prompt**: The formatted input given to an LLM, typically containing the query and necessary context.
15. **Prompt Engineering**: The practice of designing effective prompts to ensure clear and relevant outputs from an LLM.
16. **Generation**: The process by which an LLM produces text based on a given prompt.
17. **Large Language Model (LLM)**: A type of neural network model used for language understanding and generation.
18. **Temperature**: A parameter that controls the randomness of the model's output; higher values lead to more creative but less predictable results.
19. **Response**: The text output generated by the LLM, influenced by various factors including the query, context, and temperature.

